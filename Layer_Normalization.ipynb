{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ad05e7-028f-4b35-947e-d421ad54ec10",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852dd0c-918a-4823-ace1-3586035b8356",
   "metadata": {},
   "source": [
    "Here, we focus on the ADD & NORM parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84154740-7896-4d23-bfc9-5d4bf3614f67",
   "metadata": {},
   "source": [
    "Normalization:\n",
    "\n",
    "Activations of neurons will be a wide range of pos and neg values. Normalization encapsulates these values within a much smaller range and typically centered around zero and what this allows for is much more stable training as during the backprpogation phase when we actually perform a gradient step. we are taking much more even steps so it is now easier to learn and hence it is faster and also more stable training to get to the optimal position or these optimal parameter values more consistently and in a quick way.\n",
    "\n",
    "In Layer Normalization, the strategy is that we apply normalization to a neural network in this case we are going to ensure that the activation values of every neuron in every layer is normalized such that all the activation values in a layer will have like a center like zero and std of 1.\n",
    "\n",
    "Let x, y, z and o be the activation vectors for every single layer of NN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123eeb8-df84-4975-a47d-ee0bf2548ce2",
   "metadata": {},
   "source": [
    "x' = f[w_1.T x + b_1] (w_1 = weights, b_1 = bias, f = activation)\n",
    "\n",
    "y = γ_1[(x' - μ_1)/σ_1] + β_1 (μ_1 = mean of activation values of y layer, σ_1 = std of activation values of y layer, γ_1, β_1 = learnable params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b56574-16d6-409f-8c99-73a338ae9c29",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "[ 0.2 0.1 0.3\n",
    "  0.5 0.1 0.1 ] -> 2 words 3 dimensions\n",
    "\n",
    "μ_11 = 1/3 [0.2+0.1+0.3] = 0.2\n",
    "μ_21 = 1/3[0.5+0.1+0.1] = 0.233\n",
    "\n",
    "σ_11 = (1/3{[0.2 - 0.2]^2 + [0.1 - 0.2]^2 + [0.3 - 0.2]^2})^(1/2)\n",
    "     = 0.08164\n",
    "σ_21 = (1/3{[0.5 - 0.233)^2 + [0.1 - 0.233]^2 + [0.1 - 0.233]^2})^(1/2)\n",
    "     = 0.1885\n",
    "\n",
    "y = (x - μ)/σ\n",
    "y = [ 0     -1.2248 1.2248\n",
    "      1.414 -0.707  -0.707 ]\n",
    "\n",
    "out = γ * y + β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94011b9d-ef02-4305-b277-3851410724cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4ce32c-7e01-4d54-a40f-71aa1d9f72fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "B, S, E = inputs.size()\n",
    "inputs = inputs.reshape(S, B, E)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7653e5a-b7b1-4edf-8ab9-b5017d5a6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f9e937-40a1-4b4c-baba-74aa6c7bde29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size(), beta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34373b9a-de84-41cf-8e8b-ac67ae8ac4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the dimensions for which we want to compute layer normalization that is the \n",
    "# batch dimension as well as the embedding dimension\n",
    "dims = [-(i+1) for i in range(len(parameter_shape))]\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfabce2b-77e1-45c9-a3ee-83b1283f4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim=dims, keepdim=True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a73848d-b72a-4919-84d8-684c052dd53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs-mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a923e234-3339-4c22-82ca-4fb3b46538fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (inputs - mean) / std\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7cb898-9c6d-4e25-bf0f-fda0284bc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = gamma * y + beta\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e3fb7-5e22-4ebf-8659-6e953aeab11f",
   "metadata": {},
   "source": [
    "## Layer Normalization Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa89ff93-0b77-4fc3-aa39-105de6e1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LayerNormalization():\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
    "        out = self.gamma * y  + self.beta\n",
    "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f2ae30-d193-47c0-94e6-fb9b63924d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.0179,  0.4530,  0.4010, -0.2802,  0.5412,  1.4781, -0.2056,\n",
      "          -0.3623],\n",
      "         [ 2.0039, -0.1214,  0.7030, -0.8229, -1.9977,  0.7847, -0.1746,\n",
      "          -0.4260],\n",
      "         [ 0.3596, -1.4512,  0.7291,  0.1631, -0.8912,  0.8370,  0.0927,\n",
      "          -0.9296]],\n",
      "\n",
      "        [[ 0.8030, -1.3887,  0.7416, -0.1297,  1.3427,  0.2086,  0.6719,\n",
      "           1.2836],\n",
      "         [ 1.1494, -0.0777, -1.4635, -0.4438,  0.4408,  0.9419,  0.7639,\n",
      "          -1.0528],\n",
      "         [-0.6064, -0.2414, -0.5432,  1.1113,  0.2556,  0.3448,  1.6990,\n",
      "          -0.8284]],\n",
      "\n",
      "        [[ 1.2076, -1.2376,  1.0048,  0.4390,  0.4904, -0.5646,  1.7604,\n",
      "          -0.4008],\n",
      "         [-0.8284,  0.4402, -1.9090,  0.8574,  0.2157, -0.4522, -1.1233,\n",
      "           0.7318],\n",
      "         [ 0.7573,  0.0518, -1.3538, -1.3700, -0.6946,  0.9383,  0.0460,\n",
      "           0.4487]],\n",
      "\n",
      "        [[-1.8776, -0.7117, -0.6100, -1.7194, -2.0448, -0.0688,  0.3078,\n",
      "          -0.1063],\n",
      "         [ 0.9363, -1.4924, -1.5239,  0.2685, -0.0860,  0.4330, -0.7335,\n",
      "          -1.4900],\n",
      "         [ 0.6178,  0.3784, -0.7198, -1.5777, -0.6204, -1.1036, -0.7259,\n",
      "           0.6369]],\n",
      "\n",
      "        [[ 0.7527, -0.5880,  0.7373, -0.8214,  0.1541, -2.5132,  0.1863,\n",
      "           0.0737],\n",
      "         [ 0.2281, -0.0210, -0.9744, -0.4952, -0.1544,  0.9593,  0.1141,\n",
      "          -0.5005],\n",
      "         [ 0.3033,  0.3400,  0.4260, -0.0338,  1.8173, -0.3955,  0.2140,\n",
      "          -0.4962]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 8 \n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
    "\n",
    "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a8094e-ce1f-4c34-b0ce-79c49b1865bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = LayerNormalization(inputs.size()[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ccd963-dbfb-4867-bc07-dabc521aee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[ 0.2509],\n",
      "         [-0.0064],\n",
      "         [-0.1363]],\n",
      "\n",
      "        [[ 0.4416],\n",
      "         [ 0.0323],\n",
      "         [ 0.1489]],\n",
      "\n",
      "        [[ 0.3374],\n",
      "         [-0.2585],\n",
      "         [-0.1470]],\n",
      "\n",
      "        [[-0.8538],\n",
      "         [-0.4610],\n",
      "         [-0.3893]],\n",
      "\n",
      "        [[-0.2523],\n",
      "         [-0.1055],\n",
      "         [ 0.2719]]])\n",
      "Standard Deviation \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[0.5693],\n",
      "         [1.1192],\n",
      "         [0.7916]],\n",
      "\n",
      "        [[0.8311],\n",
      "         [0.8966],\n",
      "         [0.8318]],\n",
      "\n",
      "        [[0.9421],\n",
      "         [0.9202],\n",
      "         [0.8425]],\n",
      "\n",
      "        [[0.8529],\n",
      "         [0.9186],\n",
      "         [0.7790]],\n",
      "\n",
      "        [[1.0001],\n",
      "         [0.5438],\n",
      "         [0.6662]]])\n",
      "y \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.4722,  0.3551,  0.2637, -0.9331,  0.5099,  2.1557, -0.8019,\n",
      "          -1.0773],\n",
      "         [ 1.7962, -0.1028,  0.6339, -0.7296, -1.7793,  0.7069, -0.1503,\n",
      "          -0.3749],\n",
      "         [ 0.6265, -1.6612,  1.0933,  0.3782, -0.9537,  1.2296,  0.2894,\n",
      "          -1.0022]],\n",
      "\n",
      "        [[ 0.4349, -2.2024,  0.3610, -0.6875,  1.0843, -0.2804,  0.2771,\n",
      "           1.0131],\n",
      "         [ 1.2460, -0.1227, -1.6682, -0.5310,  0.4556,  1.0146,  0.8160,\n",
      "          -1.2102],\n",
      "         [-0.9080, -0.4692, -0.8320,  1.1569,  0.1283,  0.2355,  1.8634,\n",
      "          -1.1748]],\n",
      "\n",
      "        [[ 0.9237, -1.6718,  0.7084,  0.1078,  0.1624, -0.9575,  1.5104,\n",
      "          -0.7835],\n",
      "         [-0.6194,  0.7593, -1.7937,  1.2127,  0.5153, -0.2106, -0.9399,\n",
      "           1.0762],\n",
      "         [ 1.0733,  0.2360, -1.4323, -1.4514, -0.6499,  1.2881,  0.2291,\n",
      "           0.7071]],\n",
      "\n",
      "        [[-1.2003,  0.1667,  0.2859, -1.0148, -1.3963,  0.9204,  1.3619,\n",
      "           0.8765],\n",
      "         [ 1.5210, -1.1228, -1.1571,  0.7941,  0.4082,  0.9732, -0.2966,\n",
      "          -1.1201],\n",
      "         [ 1.2927,  0.9854, -0.4242, -1.5255, -0.2967, -0.9170, -0.4320,\n",
      "           1.3172]],\n",
      "\n",
      "        [[ 1.0049, -0.3356,  0.9896, -0.5691,  0.4064, -2.2607,  0.4386,\n",
      "           0.3260],\n",
      "         [ 0.6134,  0.1554, -1.5978, -0.7166, -0.0900,  1.9581,  0.4038,\n",
      "          -0.7263],\n",
      "         [ 0.0472,  0.1023,  0.2313, -0.4589,  2.3200, -1.0019, -0.0870,\n",
      "          -1.1530]]])\n",
      "out \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.4722,  0.3551,  0.2637, -0.9331,  0.5099,  2.1557, -0.8019,\n",
      "          -1.0773],\n",
      "         [ 1.7962, -0.1028,  0.6339, -0.7296, -1.7793,  0.7069, -0.1503,\n",
      "          -0.3749],\n",
      "         [ 0.6265, -1.6612,  1.0933,  0.3782, -0.9537,  1.2296,  0.2894,\n",
      "          -1.0022]],\n",
      "\n",
      "        [[ 0.4349, -2.2024,  0.3610, -0.6875,  1.0843, -0.2804,  0.2771,\n",
      "           1.0131],\n",
      "         [ 1.2460, -0.1227, -1.6682, -0.5310,  0.4556,  1.0146,  0.8160,\n",
      "          -1.2102],\n",
      "         [-0.9080, -0.4692, -0.8320,  1.1569,  0.1283,  0.2355,  1.8634,\n",
      "          -1.1748]],\n",
      "\n",
      "        [[ 0.9237, -1.6718,  0.7084,  0.1078,  0.1624, -0.9575,  1.5104,\n",
      "          -0.7835],\n",
      "         [-0.6194,  0.7593, -1.7937,  1.2127,  0.5153, -0.2106, -0.9399,\n",
      "           1.0762],\n",
      "         [ 1.0733,  0.2360, -1.4323, -1.4514, -0.6499,  1.2881,  0.2291,\n",
      "           0.7071]],\n",
      "\n",
      "        [[-1.2003,  0.1667,  0.2859, -1.0148, -1.3963,  0.9204,  1.3619,\n",
      "           0.8765],\n",
      "         [ 1.5210, -1.1228, -1.1571,  0.7941,  0.4082,  0.9732, -0.2966,\n",
      "          -1.1201],\n",
      "         [ 1.2927,  0.9854, -0.4242, -1.5255, -0.2967, -0.9170, -0.4320,\n",
      "           1.3172]],\n",
      "\n",
      "        [[ 1.0049, -0.3356,  0.9896, -0.5691,  0.4064, -2.2607,  0.4386,\n",
      "           0.3260],\n",
      "         [ 0.6134,  0.1554, -1.5978, -0.7166, -0.0900,  1.9581,  0.4038,\n",
      "          -0.7263],\n",
      "         [ 0.0472,  0.1023,  0.2313, -0.4589,  2.3200, -1.0019, -0.0870,\n",
      "          -1.1530]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = layer_norm.forward(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
