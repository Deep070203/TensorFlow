{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6979719b-9a66-4e13-bf9d-1ef1b3040694",
   "metadata": {},
   "source": [
    "# Transformers from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5eba0b-246b-43bf-81d9-71737fe08ab0",
   "metadata": {},
   "source": [
    "Transformer [Attention Mechanism]: Encoder and Decoder. Main function is for sequence to sequence modeling [sequence is an ordered set of tokens]\n",
    "\n",
    "Encoder [Goal of Attention]: Generate vectors of high quality\n",
    "\n",
    "    Step 1: Positional Encoding of the inputs. We will get vectors of size 512 dimensions\n",
    "    Step 2: Passed into Encoder: It is going to generate another set of vectors. Through the attention\n",
    "    mechanism, vectors are going to be much more context aware and hence higher quality.\n",
    "\n",
    "Attention in Transformers:\n",
    "    Scaled Dot-Product Attention and Multi-Head Attention\n",
    "    Each word input to the transformer will have three vectors:\n",
    "        Query Vector: What am I looking for [sequence length x d(k)]\n",
    "        Key Vector: What can I offer\n",
    "        Value vector: What I actually offer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f17ef-0a75-4c32-b0ea-c48c50e628ec",
   "metadata": {},
   "source": [
    "## Self Attention for Transformer Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7528bc39-3f6b-46d9-ac36-9860bb3b995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8 # L is length of input seq\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c49f94d-7683-4a1b-b587-ffb952042fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.75093004  0.64980274 -0.2989189   0.49720336 -0.27487148  1.29621948\n",
      "  -1.65384086  1.55125904]\n",
      " [ 0.03812909  0.63177235  1.00732197  1.19658816 -0.7794206  -0.77564854\n",
      "   0.05643031  0.92131849]\n",
      " [-1.92527501 -0.23311965  0.29951544  0.15592858  0.55276723  1.73631211\n",
      "  -1.33689497 -0.08537061]\n",
      " [-1.65465802 -0.89181061  0.66088938  0.57796869 -1.20558687  1.23999494\n",
      "   0.70429926 -0.65194609]]\n",
      "K\n",
      " [[ 1.16960404 -0.42379052 -1.20586281 -0.03875967 -0.8639509   0.67110154\n",
      "  -0.81708313 -0.7727469 ]\n",
      " [-0.6672614  -1.40453763  0.86421333  0.5262034   0.33517601  0.04663314\n",
      "   0.02464463 -2.64405224]\n",
      " [ 1.53010645 -0.20130136 -0.36442526 -0.94770388  0.18970751  1.69489885\n",
      "   2.54604028 -0.26950432]\n",
      " [-1.13184107 -0.19564888 -0.4287255  -1.09966455 -1.33573119  0.74126439\n",
      "   0.62854576  1.46574372]]\n",
      "V\n",
      " [[ 1.26293968  0.18046016 -1.50498972 -0.45275779 -0.49254778  0.09240977\n",
      "   1.51714337 -0.04764808]\n",
      " [-0.89338894 -1.30319967 -0.58584499 -1.12409053  1.07243493 -1.49191288\n",
      "   1.23974833 -0.72539971]\n",
      " [ 2.02894226 -0.0097814   0.08352905  0.1063474   0.35177513 -0.00477472\n",
      "  -1.18937193  0.28341608]\n",
      " [ 2.05276101  0.50959119 -0.30388456  0.62640114 -2.54713564 -1.05011528\n",
      "   0.54625447 -0.21214757]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc445b9-50f5-4f30-9056-5ae1abece109",
   "metadata": {},
   "source": [
    "### Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d372e-1e91-4398-9ee3-13be649ac535",
   "metadata": {},
   "source": [
    "$$ \\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg) $$\n",
    "\n",
    "$$ \\text{new V} = \\text{self attention}.V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532fa5be-21ef-4165-9911-c227b44b3e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.20405952, -5.58449039, -1.82807199,  1.1665599 ],\n",
       "       [-2.08942672, -2.14463781, -3.13707311, -0.06245023],\n",
       "       [-0.67423161,  2.41200346, -3.48891673,  1.5081227 ],\n",
       "       [-0.57464896,  4.62682727,  0.70096552,  3.14498234]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)\n",
    "\n",
    "# Here, it focuses on the affinity of the word towards another words. 1st line is for 1st word and each columns represents affinity towards another word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d938d43-7b5e-4f65-b5b2-db15e99eaf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9405251283393438, 1.1344256995217092, 6.967783515763168)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why we need sqrt(d_k) in denominator (to stabilize the product)\n",
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0bb753e-a520-4d4d-bd54-2c4e7677b114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9405251283393438, 1.1344256995217092, 0.8709729394703959)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "829b6d19-16a1-493d-b325-90b450e36cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77925272, -1.97441551, -0.64632105,  0.41244121],\n",
       "       [-0.7387239 , -0.75824397, -1.10912283, -0.02207949],\n",
       "       [-0.23837687,  0.852772  , -1.23351834,  0.53320189],\n",
       "       [-0.20316909,  1.63583047,  0.24782874,  1.11191917]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5abc42-4f04-42e7-a469-893469c5768f",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2de13e-8386-4932-90d8-bc583062491c",
   "metadata": {},
   "source": [
    "This is to ensure words don't get context from words generated in the future\n",
    "\n",
    "Not required in encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b836f28-5eae-4e29-a312-c1601f6fa6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a triangular matrix and will simulate the fact that the first word will \n",
    "# only look at itself, second will look at 1 and 2 and so on..\n",
    "mask = np.tril(np.ones( (L, L) ))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ca8c14-8b5b-431d-a14b-6c6f56b13dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming 0 to inf and 1 to 0. 0 and inf coz of the softmax operation\n",
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e64d5302-4f91-4cdd-a302-28655e331954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77925272,        -inf,        -inf,        -inf],\n",
       "       [-0.7387239 , -0.75824397,        -inf,        -inf],\n",
       "       [-0.23837687,  0.852772  , -1.23351834,        -inf],\n",
       "       [-0.20316909,  1.63583047,  0.24782874,  1.11191917]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking to get no context from future words\n",
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914379a1-3207-46b0-b8bd-dd54a0f83caf",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac02783-0c0a-4c9c-89d5-7388722fb8f2",
   "metadata": {},
   "source": [
    "$$ \\text{softmax} = \\frac{e^{x_i}}{\\sum_j e^x_j} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43164f7e-e112-4202-8947-1092aeef8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a vector into a probability distribution\n",
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10537106-13c0-4352-95c1-c43665b3056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = softmax(scaled + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f78f93-4d14-45fc-ad87-04096c8835d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.50487986, 0.49512014, 0.        , 0.        ],\n",
       "       [0.23002443, 0.68494217, 0.0850334 , 0.        ],\n",
       "       [0.07945841, 0.49981266, 0.12474   , 0.29598893]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abef56fd-af3a-4ab9-bd9b-23946c76c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26293968,  0.18046016, -1.50498972, -0.45275779, -0.49254778,\n",
       "         0.09240977,  1.51714337, -0.04764808],\n",
       "       [ 0.19529796, -0.5541297 , -1.04990266, -0.78514815,  0.28230668,\n",
       "        -0.69202028,  1.3797995 , -0.38321656],\n",
       "       [-0.14888492, -0.85193791, -0.74035159, -0.86503928,  0.65117052,\n",
       "        -1.00102355,  1.09699962, -0.48371724],\n",
       "       [ 0.51450888, -0.48740339, -0.49192389, -0.39913651, -0.21316402,\n",
       "        -1.0497523 ,  0.75351473, -0.39379   ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better encapsulate context of a word\n",
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6ba3d3a-6021-4200-875e-ac74656aee0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26293968,  0.18046016, -1.50498972, -0.45275779, -0.49254778,\n",
       "         0.09240977,  1.51714337, -0.04764808],\n",
       "       [-0.89338894, -1.30319967, -0.58584499, -1.12409053,  1.07243493,\n",
       "        -1.49191288,  1.23974833, -0.72539971],\n",
       "       [ 2.02894226, -0.0097814 ,  0.08352905,  0.1063474 ,  0.35177513,\n",
       "        -0.00477472, -1.18937193,  0.28341608],\n",
       "       [ 2.05276101,  0.50959119, -0.30388456,  0.62640114, -2.54713564,\n",
       "        -1.05011528,  0.54625447, -0.21214757]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac555021-ec73-47e0-961b-de4394af9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole function\n",
    "def softmax(x):\n",
    "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "  d_k = q.shape[-1]\n",
    "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "  if mask is not None:\n",
    "    scaled = scaled + mask\n",
    "  attention = softmax(scaled)\n",
    "  out = np.matmul(attention, v)\n",
    "  return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80f58b15-eeb5-4e63-89ba-70582c1ef91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.75093004  0.64980274 -0.2989189   0.49720336 -0.27487148  1.29621948\n",
      "  -1.65384086  1.55125904]\n",
      " [ 0.03812909  0.63177235  1.00732197  1.19658816 -0.7794206  -0.77564854\n",
      "   0.05643031  0.92131849]\n",
      " [-1.92527501 -0.23311965  0.29951544  0.15592858  0.55276723  1.73631211\n",
      "  -1.33689497 -0.08537061]\n",
      " [-1.65465802 -0.89181061  0.66088938  0.57796869 -1.20558687  1.23999494\n",
      "   0.70429926 -0.65194609]]\n",
      "K\n",
      " [[ 1.16960404 -0.42379052 -1.20586281 -0.03875967 -0.8639509   0.67110154\n",
      "  -0.81708313 -0.7727469 ]\n",
      " [-0.6672614  -1.40453763  0.86421333  0.5262034   0.33517601  0.04663314\n",
      "   0.02464463 -2.64405224]\n",
      " [ 1.53010645 -0.20130136 -0.36442526 -0.94770388  0.18970751  1.69489885\n",
      "   2.54604028 -0.26950432]\n",
      " [-1.13184107 -0.19564888 -0.4287255  -1.09966455 -1.33573119  0.74126439\n",
      "   0.62854576  1.46574372]]\n",
      "V\n",
      " [[ 1.26293968  0.18046016 -1.50498972 -0.45275779 -0.49254778  0.09240977\n",
      "   1.51714337 -0.04764808]\n",
      " [-0.89338894 -1.30319967 -0.58584499 -1.12409053  1.07243493 -1.49191288\n",
      "   1.23974833 -0.72539971]\n",
      " [ 2.02894226 -0.0097814   0.08352905  0.1063474   0.35177513 -0.00477472\n",
      "  -1.18937193  0.28341608]\n",
      " [ 2.05276101  0.50959119 -0.30388456  0.62640114 -2.54713564 -1.05011528\n",
      "   0.54625447 -0.21214757]]\n",
      "New V\n",
      " [[ 1.26293968  0.18046016 -1.50498972 -0.45275779 -0.49254778  0.09240977\n",
      "   1.51714337 -0.04764808]\n",
      " [ 0.19529796 -0.5541297  -1.04990266 -0.78514815  0.28230668 -0.69202028\n",
      "   1.3797995  -0.38321656]\n",
      " [-0.14888492 -0.85193791 -0.74035159 -0.86503928  0.65117052 -1.00102355\n",
      "   1.09699962 -0.48371724]\n",
      " [ 0.51450888 -0.48740339 -0.49192389 -0.39913651 -0.21316402 -1.0497523\n",
      "   0.75351473 -0.39379   ]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.50487986 0.49512014 0.         0.        ]\n",
      " [0.23002443 0.68494217 0.0850334  0.        ]\n",
      " [0.07945841 0.49981266 0.12474    0.29598893]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a83fc-ce8c-4661-ab6e-00aec44b53e9",
   "metadata": {},
   "source": [
    "## Multi-Head Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04a794-2b34-400d-a889-bdaa03728d76",
   "metadata": {},
   "source": [
    "Take a word. It is converted into a 512 dimension vector. Then, it is broken down into three vectors q, k, v (512 x 1). Each of these vectors are also broken up into separate pieces. \n",
    "\n",
    "Each piece is going to be a part to make an attention head. They are fed into an attention unit. Then, we generate an attention matrix which is a sequence by sequence length.\n",
    "\n",
    "It is a probability distribution so the rows add up to one. \n",
    "\n",
    "Each head will have its own matrix.\n",
    "\n",
    "This will then generate other output vectors that are concatenated to generate a vector with good contextual awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f0ba0b9-38fd-4a90-a376-27b9a0f652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d3d5be0-68df-4376-b880-c91199fdcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4 # len of my inp sentence\n",
    "batch_size = 1 # help in parallel processing\n",
    "input_dim = 512 # vec dim of every word that goes into the attention unit \n",
    "d_model = 512 # the output of the attention unit\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) ) # randomly sampled input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfc8c1d9-9fa4-4deb-9991-e5d86503cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23036767-9d6f-4361-aa48-3dbe859f77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3 * d_model) # create query, key and value vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ae3e563-b656-45b3-acee-a87c745438f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv_layer(x) # Generate qkv vector\n",
    "qkv.shape # 1 batch, 4 words, each word vec is 1536 in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3b6d7c-f064-4b6b-a03c-5cdf650188a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cafd43e-242e-4608-a0e1-3a896127d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# considering 8 attention heads\n",
    "num_heads = 8\n",
    "head_dim = d_model // num_heads # 512/8 = 64\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20625634-e6b1-40c7-a82e-79e4aec2bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3 * head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bc78786-6b27-49fd-8cab-21d581bc148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, -1) # breakdown by last dim\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce49cf-a207-48a1-b3c6-20d341a17f02",
   "metadata": {},
   "source": [
    "### Self Attention for multiple heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5f912a1-5498-4cc8-9a23-fb2e32dece9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) # tensors are 4 dim and not 2 dim matrix so use transpose and not .T along with the dimensions\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8017696-acbf-4fe7-af21-b42cd435e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t3/kt2c35md3j94j140w02n_3mh0000gn/T/ipykernel_41404/3717780648.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3679.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12f8fedf-2bde-414a-aa7f-ebdc0ee1e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3455, -1.1219],\n",
       "        [ 1.2139, -0.0994],\n",
       "        [-0.1949,  0.6007]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy example\n",
    "y = torch.randn(2,3)\n",
    "torch.transpose(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0583884f-8dc0-49f9-a300-8ed65627ff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3455, -1.1219],\n",
       "        [ 1.2139, -0.0994],\n",
       "        [-0.1949,  0.6007]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a22f773a-c3e4-4b47-8fbc-0d36e6eec09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking\n",
    "mask = torch.full(scaled.size(), float('-inf')) # fill up with -inf values\n",
    "mask = torch.triu(mask, diagonal = 1) # triangular matrix\n",
    "mask[0][1] # mask for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "854fb182-f998-4682-b88a-efa1a8f27ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2707,    -inf,    -inf,    -inf],\n",
       "        [-0.3121, -0.1627,    -inf,    -inf],\n",
       "        [ 0.0224, -0.3699, -0.8967,    -inf],\n",
       "        [-0.1992, -0.1902,  0.1302, -0.1646]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "160a292a-0c5e-4386-a0cf-2d6d9bc6cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5331561-3560-46f8-ae9f-cbb96bf9c2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42657718941306677"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "np.exp(-0.3121) / (np.exp(-0.3121) + np.exp(-0.01627))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adcb576d-420a-45ff-bb18-787f8aee2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "961b14db-696b-4b7f-b3b1-1f2339e52412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e10cf8d-d64c-4092-86c7-b271693042c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4627, 0.5373, 0.0000, 0.0000],\n",
       "        [0.4821, 0.3256, 0.1923, 0.0000],\n",
       "        [0.2255, 0.2276, 0.3135, 0.2335]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "646e96a6-afdf-445b-9ca0-389db6f8b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "744c3df0-29f6-45dc-8127-e0bb33196809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9367d14e-f6fc-42bc-a68d-67b716a33ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "125f05e4-121c-451a-8b8c-7fe008761798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4627, 0.5373, 0.0000, 0.0000],\n",
       "        [0.4821, 0.3256, 0.1923, 0.0000],\n",
       "        [0.2255, 0.2276, 0.3135, 0.2335]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention.shape\n",
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0706c0de-abb9-4a1a-853f-7b4918744bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da5f2a71-49ae-4920-821b-aa6df7163197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ea17841-0f7b-46fb-8484-e40a1f748c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Linear layer 512 x 512\n",
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30851069-8a12-46cb-9454-570378de62d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_layer(values)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a7e87-42f3-471f-8056-2b79a068336e",
   "metadata": {},
   "source": [
    "Multi-Headed Attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94943d30-1807-49c6-9522-37ad9bcc2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "# take in a constructor to initialize parameters\n",
    "# Also a forward path\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5eb4f-b4bd-47a6-885c-6cf38dce1bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
